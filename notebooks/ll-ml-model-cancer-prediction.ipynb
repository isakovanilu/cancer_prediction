{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68215e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15242de",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.model import ModelPackage\n",
    "\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "model_package_group_name = \"PipelineModelPackageGroup\"\n",
    "pipeline_name = \"linear-linear\"  # SageMaker Pipeline name\n",
    "\n",
    "# Define bucket, prefix, role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# SageMaker session\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e22b6",
   "metadata": {},
   "source": [
    "# import input data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640aabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_key = f'cancer-prediction-ml-model/test-data.csv'\n",
    "\n",
    "train_input_dir = f's3://{bucket}/{data_key}'\n",
    "\n",
    "data = pd.read_csv(train_input_dir)\n",
    "data.to_csv('input-data.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02523c0",
   "metadata": {},
   "source": [
    "# Define a Processing Step for Feature Engineering <a class=\"anchor\" id=\"training\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import argparse\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "def preprocessing_data(input_data_dir):\n",
    "    \n",
    "    bucket = input_data_dir.split('/')[2]\n",
    "    prefix = \"ll-ml-model\"\n",
    "    \n",
    "    # SageMaker session\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    input_data = pd.read_csv(input_data_dir)\n",
    "    df = input_data.copy()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_gender = LabelEncoder()\n",
    "    le_cancer_type = LabelEncoder()\n",
    "    df['outcome'] = df['outcome'].apply(lambda x: 1 if x == 'survived' else 0)\n",
    "    df['gender'] = le_gender.fit_transform(df['gender'])\n",
    "    df['cancer_type'] = le_cancer_type.fit_transform(df['cancer_type'])\n",
    "    \n",
    "    # Separate features and labels\n",
    "    X = df.drop('outcome', axis=1)\n",
    "    y = df['outcome']\n",
    "    \n",
    "    # Scale the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Convert to CSV format and save locally\n",
    "    # Ensure the label is the first column in the dataset\n",
    "    train_data = pd.concat([y_train.reset_index(drop=True), pd.DataFrame(X_train)], axis=1)\n",
    "    test_data = pd.concat([y_test.reset_index(drop=True), pd.DataFrame(X_test)], axis=1)\n",
    "    \n",
    "    # Save the datasets as CSV files without headers\n",
    "    train_data.to_csv('train.csv', index=False, header=False)\n",
    "    test_data.to_csv('validation.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    "    # Upload the data to S3\n",
    "    train_data_s3_path = sagemaker_session.upload_data(path='train.csv', bucket=bucket, key_prefix=f\"{prefix}/train\")\n",
    "    print('Saved Train data', train_data_s3_path)\n",
    "    test_data_s3_path = sagemaker_session.upload_data(path='validation.csv', bucket=bucket, key_prefix=f\"{prefix}/validation\")\n",
    "    print('Saved Validation data', test_data_s3_path)\n",
    "    return train_data_s3_path, test_data_s3_path\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('input_data_dir')\n",
    "    args = parser.parse_args()\n",
    "    preprocessing_data(args.input_data_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python preprocess.py 'test-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5bab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "prefix = \"ll-ml-model\"\n",
    "\n",
    "# Set the location of the train and validation data in S3\n",
    "\n",
    "s3_train_data = f's3://{bucket}/{prefix}/train/train.csv'\n",
    "s3_validation_data = f's3://{bucket}/{prefix}/validation/validation.csv'\n",
    "\n",
    "# Set up the Linear Learner container\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')\n",
    "\n",
    "# Create the Linear Learner estimator\n",
    "linear = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Set the hyperparameters\n",
    "linear.set_hyperparameters(\n",
    "    predictor_type='binary_classifier',\n",
    "    mini_batch_size=10\n",
    ")\n",
    "\n",
    "# Create input channels\n",
    "train_input = sagemaker.inputs.TrainingInput(s3_train_data, content_type='text/csv')\n",
    "validation_input = sagemaker.inputs.TrainingInput(s3_validation_data, content_type='text/csv')\n",
    "\n",
    "# Train the model\n",
    "linear.fit({'train': train_input, 'validation': validation_input})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.m5.large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86496e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete enpoint\n",
    "linear_predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac69453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Register the model in the SageMaker Model Registry\n",
    "model_package = linear.register(\n",
    "    content_types=[\"text/csv\"],                       # input content type\n",
    "    response_types=[\"text/csv\"],                      # output content type\n",
    "    inference_instances=[\"ml.m5.large\"],              # instance for inference\n",
    "    transform_instances=[\"ml.m5.large\"],              # instance for batch transform jobs\n",
    "    model_package_group_name=model_package_group_name # model package group name for versioning\n",
    ")\n",
    "\n",
    "print(f\"Model package ARN: {model_package.model_package_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700cbc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
